<!doctype html>
<html>
<head>
<meta charset="utf-8"/>
<title>Live Code a Language as Instrument</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="css/hoodie.css">
<link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="css/normalize.css">
<link rel="stylesheet" href="css/skeleton.css">
<link rel="stylesheet" href="css/codemirror.css">
<link rel="stylesheet" href="css/github.min.css">

<script src="js/jquery.min.js"></script>

<script src="js/marked.js"></script>
<script src="js/highlight.min.js"></script>
<script src="js/hljs/javascript.min.js"></script>


<style>
/* see http://getskeleton.com/ */
html { font-size: 50%; } 
table { width:100%; }
img { width: 100%; max-width: 100%; }



</style>
</head>
<body>

<script type="bogus" id="sourcetext">

# Live Code a Language as Instrument

<button class="button-primary" onclick="window.location.href='index.html'">Introduction</button>
<button onclick="window.location.href='tutorial.html'">Parsing tutorial</button>
<button onclick="window.location.href='vm.html'">Target language</button>
<button onclick="window.location.href='editor.html'">Editor</button>

In this workshop participants will design and develop idiosyncratic (perhaps even esoteric) languages for live coding. 
 
The notion of the programming language being a musical instrument is particularly well established within live coding research. Performers and live coders have utilized languages with features specially oriented to the domain of computer music. Languages work by reframing the terms of work into affordances and constraints relevant to the domain, making them more readily available and discoverable. Thus many performers and live coders have explored designing new “mini-languages” to serve as scaffolds for externalising musical thinking, through which we can be more able to engage directly with music through high-level representations. Some are so idiosyncratic and model-constrained to be considered initiating a miniature genre or compositional form.

In this workshop participants will create mini-languages via a readily-accessible browser-based code editor, using open-source software we provide. The workshop will give a gentle introduction to the construction of grammars for parsing, using friendly browser-based libraries, with which participants will design their own mini-languages for defining musical patterns. No experience in any of these specific technologies is necessary. However, some programming experience will be helpful (especially in JavaScript). An open-source browser-based editing environment and support library will be provided to participants. This environment leverages the codemirror and peg.js projects, and can dynamically evaluate code to communicate via websockets with other platforms for generating audiovisual content. We will reserve time for participants to experiment with other languages created in the workshop, so that they can obtain feedback and inspiration from each other. Participants will leave with the knowledge required to continue development of their language on their own.


**We recommend using the [Google Chrome](https://support.google.com/chrome/answer/95346?co=GENIE.Platform%3DDesktop&hl=en-GB) browser for this workshop.**

---

We're going to design languages for live coding. We don't have much time, so they're going to have to be simple, but that doesn't mean they can't be unusual ([for inspiration, look at this list of esoteric languages here](https://esolangs.org/wiki/Language_list)). Our languages are going to be input as raw text, and our job is to build the parser that can understand this text. Parsing is the general problem of turning raw text into meaningfully-structured data and/or actions, such as sonic events. 

We're going to do most of this using web-based technologies, supported by JavaScript. For example, grammars will be implemented using the [PEG.js](http://pegjs.org) library, the text editor uses the [CodeMirror](http://codemirror.net/) library, our example sounds are generated from the [Gibberish](http://www.charlie-roberts.com/gibberish/) library, etc. -- but you don't really need to know all of this, as they're already built-in to our workshop pages. One good thing though is that you can take your languages with you -- the grammars are designed for [Peg.js](http://pegjs.org/online) but follow a more general formalism that can be embedded in other places and systems.

As language creators, we need to decide what kinds of text fragments will turn into what kinds of actions. We need to know:

1. **What kinds of text fragments can we recognize?** We'll look at a variety of examples. We can start by [learning about Parsing Expression Grammars with our tutorial here](tutorial.html), and [elsewhere](https://en.wikipedia.org/wiki/Parsing_expression_grammar)

2. **What kinds of actions can we make?** For this workshop, the kinds of actions we can make are instrument note triggers, instrument parameter changes, scheduling of events, and some other things. We can learn about what kinds of things we can generate by [looking at our target language here](vm.html).
	
3. **How to specify the mapping between text and action?** We'll work on new mappings by live coding in [the editor](editor.html)

<div class="iframe-container-16x9">
  <iframe frameborder=0 src="https://www.youtube.com/embed/3T8MrcPQ9HY?rel=0" allowfullscreen></iframe>
</div>


---

@Copyright 2017 Graham Wakefield & Charlie Roberts

</script>

<div class="container">

	<div class="row" style="margin-top: 5%">
		<div class="full column" id="main_body">
		</div>
	</div>
</div>



<script>

var body = document.getElementById('sourcetext').innerText;
document.getElementById('main_body').innerHTML = marked(body);

</script>

</body>
</html>
